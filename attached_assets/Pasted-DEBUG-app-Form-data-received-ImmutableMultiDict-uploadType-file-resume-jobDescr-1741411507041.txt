DEBUG:app:Form data received: ImmutableMultiDict([('uploadType', 'file'), ('resume', ''), ('jobDescriptionType', 'url'), ('job_description', ''), ('job_url', 'https://boards.greenhouse.io/anthropic/jobs/4561280008')])
DEBUG:services.job_description_processor:Attempting to extract content from URL: https://boards.greenhouse.io/anthropic/jobs/4561280008
DEBUG:services.job_description_processor:Attempting extraction with trafilatura...
DEBUG:trafilatura.downloads:sending request: https://boards.greenhouse.io/anthropic/jobs/4561280008
DEBUG:urllib3.connectionpool:https://boards.greenhouse.io:443 "GET /anthropic/jobs/4561280008 HTTP/1.1" 200 None
DEBUG:trafilatura.main_extractor:['blockquote', 'code', 'del', 'head', 'hi', 'lb', 'list', 'p', 'pre', 'quote', 'table', 'td', 'th', 'tr']
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div Annual Salary:
DEBUG:trafilatura.main_extractor:discarding element: div $320,000—$485,000 USD
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:extra in p: p Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.
DEBUG:trafilatura.main_extractor:(.//*[self::article or self::div or self::main or self::section][ contains(@id, "content-main") or contains(@class, "content-main") or contains(@class, "content_main") or contains(@id, "content-body") or contains(@class, "content-body") or contains(@id, "contentBody") or contains(@class, "content__body") or contains(translate(@id, "CM","cm"), "main-content") or contains(translate(@class, "CM","cm"), "main-content") or contains(translate(@class, "CP","cp"), "page-content") or @id="content" or @class="content"])[1]
DEBUG:trafilatura.readability_lxml:Top 5: div 97.98541924095322
DEBUG:trafilatura.readability_lxml:Top 5: div 81.32999999999998
DEBUG:trafilatura.readability_lxml:Top 5: div 60.66499999999999
DEBUG:trafilatura.readability_lxml:Top 5: div 43.445
DEBUG:trafilatura.readability_lxml:Top 5: div 40.0
DEBUG:trafilatura.readability_lxml:Removed  6.140 div with weight 0 cause it has too short content length 23 without a single image.
DEBUG:trafilatura.readability_lxml:Removed 30.790 div with weight 0 cause it has less than 3x <p>s than <input>s.
DEBUG:trafilatura.readability_lxml:Removed 30.790 div with weight 0 cause it has less than 3x <p>s than <input>s.
DEBUG:trafilatura.readability_lxml:Removed  0.000 div with weight 0 cause it has less than 3x <p>s than <input>s.
DEBUG:trafilatura.external:extracted length: 5641 (algorithm) 5815 (extraction)
DEBUG:trafilatura.external:extraction values: 5815 5641 for None
DEBUG:trafilatura.external:using custom extraction: None
DEBUG:trafilatura.core:not enough comments: None
DEBUG:services.job_description_processor:Successfully extracted content with trafilatura
DEBUG:services.job_description_processor:Extracted title from trafilatura: About Anthropic
DEBUG:services.file_parser:File validation - Name: joshua_oliphant_resume.pdf, Extension: pdf
DEBUG:services.file_parser:File MIME type: application/pdf
DEBUG:services.file_parser:Parsing file: joshua_oliphant_resume.pdf
DEBUG:services.file_parser:File MIME type for parsing: application/pdf
DEBUG:services.file_parser:Parsed PDF content length: 7619
ERROR:app:Error processing resume: (psycopg2.ProgrammingError) can't adapt type 'dict'
[SQL: INSERT INTO job_description (title, content, url, created_at, user_id) VALUES (%(title)s, %(content)s, %(url)s, %(created_at)s, %(user_id)s) RETURNING job_description.id]
[parameters: {'title': 'Job Description', 'content': {'title': 'About Anthropic', 'content': 'About Anthropic\nAnthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want  ... (5707 characters truncated) ... e working hours, and a lovely office space in which to collaborate with colleagues.', 'url': 'https://boards.greenhouse.io/anthropic/jobs/4561280008'}, 'url': None, 'created_at': datetime.datetime(2025, 3, 8, 5, 23, 55, 782411), 'user_id': 1}]
(Background on this error at: https://sqlalche.me/e/20/f405)
DEBUG:routes.jobs:Processing job URL submission
DEBUG:routes.jobs:Form data received: ImmutableMultiDict([('url', 'https://boards.greenhouse.io/anthropic/jobs/4561280008')])
DEBUG:services.file_parser:File validation - Name: joshua_oliphant_resume.pdf, Extension: pdf
DEBUG:services.file_parser:File MIME type: application/pdf
DEBUG:services.file_parser:Parsing file: joshua_oliphant_resume.pdf
DEBUG:services.file_parser:File MIME type for parsing: application/pdf
DEBUG:services.file_parser:Parsed PDF content length: 7619
DEBUG:routes.jobs:Received URL: https://boards.greenhouse.io/anthropic/jobs/4561280008
DEBUG:routes.jobs:Resume content received: True (length: 7619)
DEBUG:routes.jobs:Extracting job description from URL...
DEBUG:services.job_description_processor:Attempting to extract content from URL: https://boards.greenhouse.io/anthropic/jobs/4561280008
DEBUG:services.job_description_processor:Attempting extraction with trafilatura...
DEBUG:trafilatura.downloads:sending request: https://boards.greenhouse.io/anthropic/jobs/4561280008
DEBUG:urllib3.connectionpool:https://boards.greenhouse.io:443 "GET /anthropic/jobs/4561280008 HTTP/1.1" 200 None
DEBUG:trafilatura.main_extractor:['blockquote', 'code', 'del', 'head', 'hi', 'lb', 'list', 'p', 'pre', 'quote', 'table', 'td', 'th', 'tr']
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:discarding element: div Annual Salary:
DEBUG:trafilatura.main_extractor:discarding element: div $320,000—$485,000 USD
DEBUG:trafilatura.main_extractor:discarding element: div None
DEBUG:trafilatura.main_extractor:extra in p: p Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.
DEBUG:trafilatura.main_extractor:(.//*[self::article or self::div or self::main or self::section][ contains(@id, "content-main") or contains(@class, "content-main") or contains(@class, "content_main") or contains(@id, "content-body") or contains(@class, "content-body") or contains(@id, "contentBody") or contains(@class, "content__body") or contains(translate(@id, "CM","cm"), "main-content") or contains(translate(@class, "CM","cm"), "main-content") or contains(translate(@class, "CP","cp"), "page-content") or @id="content" or @class="content"])[1]
DEBUG:trafilatura.readability_lxml:Top 5: div 97.98541924095322
DEBUG:trafilatura.readability_lxml:Top 5: div 81.32999999999998
DEBUG:trafilatura.readability_lxml:Top 5: div 60.66499999999999
DEBUG:trafilatura.readability_lxml:Top 5: div 43.445
DEBUG:trafilatura.readability_lxml:Top 5: div 40.0
DEBUG:trafilatura.readability_lxml:Removed  6.140 div with weight 0 cause it has too short content length 23 without a single image.
DEBUG:trafilatura.readability_lxml:Removed 30.790 div with weight 0 cause it has less than 3x <p>s than <input>s.
DEBUG:trafilatura.readability_lxml:Removed 30.790 div with weight 0 cause it has less than 3x <p>s than <input>s.
DEBUG:trafilatura.readability_lxml:Removed  0.000 div with weight 0 cause it has less than 3x <p>s than <input>s.
DEBUG:trafilatura.external:extracted length: 5641 (algorithm) 5815 (extraction)
DEBUG:trafilatura.external:extraction values: 5815 5641 for None
DEBUG:trafilatura.external:using custom extraction: None
DEBUG:trafilatura.core:not enough comments: None
DEBUG:services.job_description_processor:Successfully extracted content with trafilatura
DEBUG:services.job_description_processor:Extracted title from trafilatura: About Anthropic
DEBUG:routes.jobs:Job description extracted, title: About Anthropic, content length: 5848
DEBUG:routes.jobs:Job description saved to database with ID: 45
DEBUG:routes.jobs:Analyzing resume against job description...
DEBUG:routes.jobs:ATS analysis complete, score: 13.27
DEBUG:routes.jobs:Getting AI suggestions...
DEBUG:anthropic._base_client:Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 2000, 'messages': [{'role': 'user', 'content': '\n            As an ATS expert, analyze this resume against the job description to provide detailed, actionable feedback.\n            Format your response with the following structure using Markdown headings:\n\n            # Resume Analysis for [Position]\n\n            ## Overall Assessment\n            Provide a clear overview (2-3 sentences) evaluating how well the resume matches the job requirements, highlighting strengths and areas needing improvement.\n\n            ## Specific Improvement Suggestions\n\n            ### 1. Content Relevance & Key Skills Alignment\n            - List 3-4 specific skills/experiences from the resume that match the job requirements\n            - Identify 3-4 key missing keywords or experiences from the job description\n            - Provide 2-3 concrete suggestions for better aligning content with the role\n            - Suggest modifications to highlight relevant achievements\n\n            ### 2. Technical Skills Enhancement\n            - Review technical skills mentioned in the resume vs. job requirements\n            - Suggest specific technical areas to emphasize or add\n            - Recommend ways to demonstrate technical proficiency\n\n            ### 3. Format and Impact\n            - Evaluate current resume structure and organization\n            - Suggest improvements for better ATS optimization\n            - Recommend ways to quantify achievements\n\n            Resume:\n            Joshua Oliphant    Joshua Oliphant    360.333.0114    joshua.oliphant@hey.com    https://linkedin.com/in/joshuaoliphant      TECHNICAL SKILLS     Backend: Java, Spring Boot, Python, Django, Flask, C#, Dotnet, .Net, REST, event-driven, streaming, Lua  Cloud: AWS lambda, glue, step function, ECS, S3  Data storage and databases: Postgres, sqlite, Kafka, Kinesis, DynamoDB  Testing: Junit, Cucumber, Gatling, Test Containers, go test, unittest, pytest, MSTest  AI: Github Copilot, ChatGPT, OpenAI API, Anthropic API, Python SDKs  Monitoring: Datadog, Splunk, Prometheus, Grafana, Cloudwatch  Others: Docker, Helm, Git, Splunk, Prometheus, Datadog, Jira, Gitlab CI, CI/CD, DevOps, Bazel, make, bash, Tilt      PROFESSIONAL EXPERIENCE       Senior Software Development Engineer (SDE4) Nortal consultant at T-Mobile                                                           January 2022 – April 2024   • Led Docker containerization of Java/Spring Boot microservices, which improved application scalability and efficiency by decreasing image size by nearly 50% with Java 9 modules.   • Created an automations command line project with Python and the Click library, which streamlined many processes, including production releases and rollbacks.  • Streamlined application deployments using GitLab CI/CD pipelines and Helm for Kubernetes services, which automated reliable builds, tests, and packages, give rapid developer feedback.  • Researched and spearheaded Kafka cluster creation in Kubernetes with open-source Strimzi, , enabling fast and asynchronous event-driven microservics, and dramatically reducing costs compared to Confluent Platform.  Technical stack:   • Back-end: Microservices, Java 17, Spring, Python automation  • Platform: Kubernetes in datacenter  • Databases: Postgres, H2  • Virtualization: Docker   • Testing: Junit, Gatling  • Monitoring: Splunk, Grafana  • Others: Maven, Jira, Splunk, Git, Tilt, Helm, Kafka, REST, event-driven architecture    Senior Software Development Engineer (SDE3) Nortal consultant at Motorola February 2021 – December 2021  • Developed Azure DevOps CI/CD pipelines to automate the deployment of Dotnet services to FedRamp environments.  • Focused on high-quality C#/.Net microservices development.  Technical stack:   • Back-end: C#, .Net  • Cloud: Azure  • Virtualization: Docker   • Testing: MSTest  • Others: Git, Jira, REST    Senior Software Development Engineer (SDE3) Nortal consultant at Amazon September 2020 – January 2021  • Led a team to integrate AWS services (Lambda, Kinesis, DynamoDB, S3, Glue) into an ETL data pipeline. This made the cleaned up and transformed code available to key downstream services.  • Authored Java AWS Lambdas for data processing within Step Functions, ensuring that each data processing step was reliably executed.  • Used IaC (Infrastructure as Code) with the AWS CDK (Cloud Development Kit) in Typescript to create safe repeatable infrastructure.    \n\nTechnical stack:   • Back-end: Java, AWS Lambdas  • Cloud: Amazon Web Services (AWS)  • Databases: DynamoDB  • Virtualization: None (Lambdas)   • Testing: Junit  • Monitoring: Cloudwatch  • Others: Git, Kinesis, Glue, Step Function, Lamda, IaC (CDK), ETL    Senior Software Development Engineer (SDE3) Nortal consultant at Brightloom (startup) 2020 – September 2020  • Built backend microservices with Python and Django with a consistent structure so that each subsequent service could be built quickly, increasing developer productivity.  • Built CI/CD pipelines with TravisCI to deploy Python services to Kubernetes with Helm, which delivered reliable applications with a fast developer feedback loop.  • Contributed to Terraform IaC (Infrastructure as Code), creating reliable and repeatable infrastructure creation.  Technical stack:   • Back-end: Python, Django, Microservices, REST  • Platform: Kubernetes  • Databases: Postgres, sqlite  • Virtualization: Docker   • Monitoring: Datadog  • Testing: unittest  • Others: Git, Jira, Helm, IaC (Terraform), CI/CD, TravisCI    Software Development Engineer (SDE2) Nortal consultant at Expedia August 2019 – January 2020  • Independently executed and designed a data pipeline, demonstrating complete ownership of work. This enabled Expedia to make data-driven decisions in downstream services.  • Constructed Java microservices and updated an existing Lua service, each key components of the data transformation pipeline.  • Integrated Kafka for continuous data transformation and deployed solutions on AWS ECS, showcasing cloud expertise.  Technical stack:   • Back-end: Java, Spring, Microservices, event-driven, Lua  • Cloud: AWS  • Virtualization: Docker   • Testing: Junit  • Monitoring: Datadog  • Others: Git, Kafka, ECS, CI/CD     Software Engineer 2 for Kubernetes Platform Team Nordstrom August 2018 – August 2019   • Led Kubernetes Customer Engineering Initiative which included onboarding new teams, held office hours and one-onones to provide guidance on Kubernetes best practices. This provided a consistent “public” face for the team, and increased my teams’ overall productivity, as well as improving the Kubernetes developer experience across Nordstrom.  • Managed large-scale Kubernetes clusters (50+ nodes) for critical workloads.  • Provided on-call support, ensuring system stability and performance.  • Contributed to automation in Python, bash, and make.  • Participated in monthly disaster recovery exercises, ensure the smooth recovery to multiple levels of disasters, from service to namespace to full cluster recovery.  Technical stack:   • Back-end: Golang, Python, bash, makefiles  • Cloud: AWS, GCP  • Platform: Kubernetes  • Virtualization: Docker   • Testing: go test  • Monitoring: Prometheus, Grafana, Datadog  • Others: Bazel, Gitlab, Gitlab CI, Gitlab issue tracking, Helm, Prometheus, Datadog, S3  \n\n   Software Engineer 1-2 for POS Modernization Team  Nordstrom August 2015 – August 2018   • Played a key role in the Point-of-Sale system\'s transition from a monolith to a microservices architecture.  • Became an Apache Kafka SME, deepening expertise in event-driven architecture that enabled me to deliver real-time data transformations.  • Containerized services for deployment to Kubernetes.  Technical stack:   • Back-end: Java, Spring  • Cloud: AWS  • Platform: Kubernetes  • Virtualization: Docker   • Testing: Junit, Cucumber  • Monitoring: Datadog, Splunk  • Others: Maven, Gitlab, Jira, Confluence, Splunk, Datadog, Kafka      EDUCATION       Seattle University                                                                                                                                                            Seattle, WA  Bachelor of Science, Computer Science                                                                                                September 2014 – June 2016    Seattle Central                                                                                                                                                                 Seattle, WA  Associates degree                                                                                                                                  September 2012 – June 2014     RECENT AI SIDE PROJECTS    • AI Chat website o Python and Flask on the backend  o htmx and Tailwind on the frontend   o Uses the OpenAI Assistant API to power that chat functionality  • PDF Benchmarker  o Part of first cohort of DeepLearning.ai student to build open source project that utilize learned skills.   o The current project is a PDF benchmarker to understand the best PDF scraping tools for RAG applications  \n\n            Job Description:\n            About Anthropic\nAnthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout the role\nAnthropic is seeking talented and experienced Software Engineers to join our API team and help build the world\'s most trusted AI platform for developers. Since launch, the Anthropic API has seen rapid growth and adoption by companies of all sizes to build AI applications with our industry-leading models. The API serves as the primary channel for safely and broadly distributing AI\'s benefits across all sectors of the economy. You\'ll work on building and scaling frontier model capabilities while ensuring they\'re easy to use, safe, and provide a world-class developer experience.\nWe have two specialized teams that are currently hiring. Team placement occurs after the interview process, taking into account your interests and experience alongside organizational needs:\nAPI Capabilities: You\'ll work on shipping the world\'s most intelligent and capable APIs, partnering directly with research to bring frontier capabilities to developers. This team owns core capabilities including vision, tool use, computer use, and prompt caching. Your work will directly impact how developers interact with our most advanced models.\nAPI Knowledge: You\'ll focus on transforming Claude into a true knowledge worker by ensuring the model has access to and understanding of the right knowledge at the right time. You\'ll work on making it possible for developers to securely give Claude access to their data while automatically processing and retrieving relevant information. You\'ll partner directly with research to bring state-of-the-art retrieval advancements to developers.Responsibilities:\n- Design and implement products that we launch in the Anthropic API, serving hundreds of thousands of developers\n- Partner with research teams to productize cutting-edge model capabilities\n- Participate in API design reviews to ensure consistent, intuitive developer experiences\n- Collaborate with cross-functional teams to ship a world-class product\n- Support and debug production issues through on-call rotations\n- Design processes (e.g. postmortem review, incident response, on-call rotations) that help the team operate effectively and never fail the same way twice\nYou might be a good fit if you:\n- Have 8+ years of relevant industry experience, 3+ years leading large scale, complex projects or teams as an engineer or tech lead\n- Are passionate about designing tasteful APIs and developer-focused products\n- Enjoy talking directly with users and view "product" as part of your job\n- Can work independently and thrive in a fast-paced environment\n- Have deep expertise in distributed systems and API architecture\n- Have excellent written and verbal communication skills to build consensus with stakeholders\nTechnical Stack\n- Languages: Python, TypeScript\n- Frameworks: FastAPI, React\n- Infrastructure: GCP, Kubernetes, Cloud Run\n- Databases: PostgreSQL (AlloyDB), Vector Stores\n- Tools: Statsig, Prometheus, Grafana\nThe expected salary range for this position is:\nLogistics\nEducation requirements: We require at least a Bachelor\'s degree in a related field or equivalent experience.\nLocation-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship: We do sponsor visas! However, we aren\'t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you\'re interested in this work. We think AI systems like the ones we\'re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow we\'re different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We\'re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues.\n\n            Provide detailed, actionable feedback for each section, maintaining the markdown heading hierarchy. \n            Ensure recommendations are specific and tailored to both the resume content and job requirements.\n            '}], 'model': 'claude-3-7-sonnet-20250219'}}
DEBUG:anthropic._base_client:Sending HTTP Request: POST https://api.anthropic.com/v1/messages
DEBUG:httpcore.connection:close.started
DEBUG:httpcore.connection:close.complete
DEBUG:httpcore.connection:connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(1, 9, True), (6, 5, 60), (6, 6, 5), (6, 4, 60)]
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7b7b420150>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7b7df45520> server_hostname='api.anthropic.com' timeout=5.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7b7b420f90>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Mar 2025 05:24:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'1000'), (b'anthropic-ratelimit-requests-remaining', b'999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-08T05:23:56Z'), (b'anthropic-ratelimit-input-tokens-limit', b'40000'), (b'anthropic-ratelimit-input-tokens-remaining', b'37000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-08T05:24:01Z'), (b'anthropic-ratelimit-output-tokens-limit', b'16000'), (b'anthropic-ratelimit-output-tokens-remaining', b'16000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-08T05:24:15Z'), (b'anthropic-ratelimit-tokens-limit', b'56000'), (b'anthropic-ratelimit-tokens-remaining', b'53000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-08T05:24:01Z'), (b'request-id', b'req_013Pk15dw2chAFW5kxXpD6Je'), (b'anthropic-organization-id', b'df476545-6878-4521-a732-d3560cdb1aed'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91cfe745985aa3ad-SEA'), (b'Content-Encoding', b'gzip')])
INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:anthropic._base_client:HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Sat, 08 Mar 2025 05:24:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '1000', 'anthropic-ratelimit-requests-remaining': '999', 'anthropic-ratelimit-requests-reset': '2025-03-08T05:23:56Z', 'anthropic-ratelimit-input-tokens-limit': '40000', 'anthropic-ratelimit-input-tokens-remaining': '37000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-08T05:24:01Z', 'anthropic-ratelimit-output-tokens-limit': '16000', 'anthropic-ratelimit-output-tokens-remaining': '16000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-08T05:24:15Z', 'anthropic-ratelimit-tokens-limit': '56000', 'anthropic-ratelimit-tokens-remaining': '53000', 'anthropic-ratelimit-tokens-reset': '2025-03-08T05:24:01Z', 'request-id': 'req_013Pk15dw2chAFW5kxXpD6Je', 'anthropic-organization-id': 'df476545-6878-4521-a732-d3560cdb1aed', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '91cfe745985aa3ad-SEA', 'content-encoding': 'gzip'})
DEBUG:anthropic._base_client:request_id: req_013Pk15dw2chAFW5kxXpD6Je
DEBUG:routes.jobs:AI suggestions generated, count: 53